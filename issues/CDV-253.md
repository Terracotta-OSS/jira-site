---

title: "Deadlock and data corruption when transaction size too small"
layout: issue
tags: 
permalink: /browse/CDV-253

issue_key: CDV-253
issue_numeric_sort_key: 253
issuetype: "Bug"
project: "Community Development (Terracotta Server)"
project_key: "CDV"
status: "Closed"
resolution: "Fixed"
priority: "1 Critical"
components: ""
labels: 
assignee: "hhuynh"
reporter: "rbodkin"
votes:  0
watchers: 0

created: "2007-05-03T16:14:43.000-0400"
updated: "2008-04-25T00:41:30.000-0400"
resolved: "2007-07-20T17:19:39.000-0400"

attachments:
- filename: "cdv253.zip"
  author: "rbodkin"
  size: 286.00 k
  mimeType: application/zip
- filename: "cdv253-bigtxn.zip"
  author: "rbodkin"
  size: 9.00 k
  mimeType: application/zip




---

{% raw %}

## Description

<div markdown="1" class="description">

I am testing a bulk load transaction into a hash map of hash maps. For efficiency I am inserting a moderate number of items (about 2000 changes) per operation. However, I find that if I use 2000 changes per transaction the transaction queue builds up to the maximum allowed (30) and then the L1 hangs, blocking on the queue. Moreover, it becomes impossible to connect to the L2 server from the admin console. If I kill the L1 and L2 processes and restart them, then I can't even start my L1 application. If I erase the server's persistent data then I can restart. If I lower this to 100 changes it makes more progress but eventually fails (presumably it hits the transaction size limit). Lowering this to 25 changes, it gets further still, but eventually fails (I notice that in the smaller cases I get more than 1 TxnsInBatch). It would be much better if TC would explicitly fail if a transaction exceeds the size limit (better yet if it could grow the size limit dynamically).



</div>

## Comments


{:.comment-heading}
### **Steve Harris** <span class="date">2007-05-03</span>

<div markdown="1" class="comment">

Saro, Can you look into this. I think their must be something more two this then what we know so far since we test with larger data loads than this every night :-).

</div>


{:.comment-heading}
### **Tim Eck** <span class="date">2007-05-03</span>

<div markdown="1" class="comment">

for tracking purposes, the next steps here are (1) reproduce with trunk, and (2) add more logging to determine if a something is getting permanently stuck in pending state 

</div>


{:.comment-heading}
### **Tim Eck** <span class="date">2007-05-03</span>

<div markdown="1" class="comment">

added tc.property to debug txn flow in the server  (use with care)

-Dcom.tc.l2.transactionmanager.logging.enabled=true


</div>


{:.comment-heading}
### **Ron Bodkin** <span class="date">2007-05-03</span>

<div markdown="1" class="comment">

I see the same bug in nightly build 2842. I wil ltry the new -D option when I can download the build from tonight.

</div>


{:.comment-heading}
### **Ron Bodkin** <span class="date">2007-05-04</span>

<div markdown="1" class="comment">

I tried nightly build 2864 with the new -D option when running the L2 server but I didn't see any additional logging. Was it included in this build?


</div>


{:.comment-heading}
### **Hung Huynh** <span class="date">2007-05-04</span>

<div markdown="1" class="comment">

Tim pushed the change to rev2872 so that build didn't have it yet. I just pushed another nightly build, you can use that.

</div>


{:.comment-heading}
### **Tim Eck** <span class="date">2007-05-04</span>

<div markdown="1" class="comment">

sorry, the change was revision 2872. Only if you're interested, you can track our source and what not in fisheye (http://svn.terracotta.org/fisheye/browse/Terracotta) and/or the FishEye here on this item in JIRA

</div>


{:.comment-heading}
### **Ron Bodkin** <span class="date">2007-05-07</span>

<div markdown="1" class="comment">

client and server logs. I ran the client with -Dcom.tc.l1.transactionmanager.logging.enabled=true and the server with -Dcom.tc.l2.transactionmanager.logging.enabled=true

Note that I killed the l2 server and left the client running for a while, so there are uninteresting messages at the end of that log.

Of note here is that the client maintains a flow of transactions to the server, yet the application is stalled. I believe that somehow the client is failing quietly and resubmitting doomed transactions over and over.


</div>


{:.comment-heading}
### **Ron Bodkin** <span class="date">2007-05-07</span>

<div markdown="1" class="comment">

Here's another log where the system fails quickly because I made the batch size much larger.

</div>


{:.comment-heading}
### **Saravanan Subbiah** <span class="date">2007-05-15</span>

<div markdown="1" class="comment">

From the logs you attached, I can see that the transactions are getting struck in the server for some reason. Unfortunately that is all I can tell.

Can you please attach the program that caused this ? It  can greatly help us  in solving this issue.

</div>


{:.comment-heading}
### **Ron Bodkin** <span class="date">2007-05-16</span>

<div markdown="1" class="comment">

Hi Saravanan, the program used for this test ties in with a lot of library code and can't be shared. It might be possible to capture some logs for an extra diagnostic version of the application, if you could provide a way of running that?


</div>


{:.comment-heading}
### **Fiona OShea** <span class="date">2007-05-31</span>

<div markdown="1" class="comment">

Keep watching this

</div>


{:.comment-heading}
### **Saravanan Subbiah** <span class="date">2007-06-19</span>

<div markdown="1" class="comment">

Hi Ron,

We are thinking this could be related to Out Of Memory in the L2. Just to verify, can you please rerun the test with -verbosegc -XX:+PrintGCDetails for both L1 and L2 and resend the logs ? Also can you please set -Dcom.tc.l2.cachemanager.logging.enabled=true for L2  and -Dcom.tc.l1.cachemanager.logging.enabled=true for L1 when running the test ?

This will give us more output that will help us debug.

thanks,
Saravanan

</div>


{:.comment-heading}
### **Saravanan Subbiah** <span class="date">2007-07-20</span>

<div markdown="1" class="comment">

We were able to reproduce this issue with an inhouse test. The problem could happen when a single transaction could contain changes to more than 5000 objects.

The fix was pushed into 2.4 and trunk.

</div>


{:.comment-heading}
### **Fiona OShea** <span class="date">2008-02-22</span>

<div markdown="1" class="comment">

Appears that this has been resolved months ago.

</div>



{% endraw %}
